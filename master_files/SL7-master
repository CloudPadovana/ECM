#!/bin/bash
HOSTIP=$(hostname -I | awk '{print $1}')
##################
# ELASTIQ CONFIG #
##################
EC2_ACCESS_KEY=access-key
EC2_SECRET_KEY=secret-key
EC2_URL=ec2-url
MAX_VMS=max-vms
MIN_VMS=min-vms
FLAVOR=instance-flavor
IMAGE_ID=image-id
JOBS_PER_VM=jobs-per-vm
IDLE_TIME=idle-time
KEY_NAME=key-name
SLAVE_USERDATA=slave-userdata

###########
# CA CERT #
###########
yum install -y wget epel-release
#
cd /tmp
wget http://90.147.77.142/repo/CA/tls-ca-bundle.pem
#
#################
# CONDOR CONFIG #
#################
cat << EOF >/tmp/Cluster 
###############
# SL7 Cluster #
###############
SEC_DAEMON_AUTHENTICATION = required
SEC_DAEMON_INTEGRITY = required
SEC_DAEMON_AUTHENTICATION_METHODS = password
SEC_CLIENT_AUTHENTICATION_METHODS = password,fs,gsi,kerberos
SEC_PASSWORD_FILE = /etc/condor/condor_credential
SEC_ENABLE_MATCH_PASSWORD_AUTHENTICATION = True

ALLOW_DAEMON = condor_pool@*, submit-side@matchsession
COLLECTOR_NAME = CernVM cluster at \$(CONDOR_HOST)
NEGOTIATOR_INTERVAL = 20
START = TRUE
SUSPEND = FALSE
PREEMPT = FALSE
KILL = FALSE
TRUST_UID_DOMAIN = TRUE

UPDATE_COLLECTOR_WITH_TCP = True
COLLECTOR_SOCKET_CACHE_SIZE = 1000

CONDOR_DEVELOPERS_COLLECTOR = NONE
EOF
###############
# TEST SCRIPT #
###############
cat <<EOF> /tmp/test.sh
#!/bin/bash
HOST=\$(hostname -I | awk '{print $1}')
DIR=\$(pwd)
sleep 5
echo "I'm sleeping in \$HOST"
echo ":-("
echo "More precisely in this directory \$DIR" 
echo ":-/"
sleep 20
echo "Now I'm running! So fun! :-)"
EOF
############################
# MASTER NODE INSTALLATION #
############################
cd /etc/yum.repos.d
wget http://90.147.77.142/repo/htcondor/repo.d/htcondor-stable-rhel7.repo
yum clean all
yum install -y condor-all-8.6.9
CUID=$(id condor | awk '{print $1}'| cut -d'=' -f2|cut -d'(' -f1)
CGID=$(id condor | awk '{print $2}'| cut -d'=' -f2|cut -d'(' -f1)
cat << EOF >/etc/condor/condor_config.local
DAEMON_LIST = COLLECTOR, MASTER, NEGOTIATOR, SCHEDD
CONDOR_HOST = $HOSTIP
CONDOR_ADMIN = root@$HOSTIP

# Preserve UID of submitting user
UID_DOMAIN = *
TRUST_UID_DOMAIN = True
SOFT_UID_DOMAIN = True

CONDOR_IDS = $CUID.$CGID
QUEUE_SUPER_USERS = root, condor
HIGHPORT = 42000
LOWPORT = 41000
EOF
cat /tmp/Cluster > /etc/condor/config.d/SL7
#
/usr/sbin/condor_store_cred -p 12345 add -f /etc/condor/condor_credential
#
service condor start
#
yum localinstall -y http://90.147.77.142/repo/elastiq/rhel7/python-elastiq-0.9.10-1.py27.noarch.rpm
#
cat /tmp/tls-ca-bundle.pem >> /usr/lib/python2.7/site-packages/boto/cacerts/cacerts.txt
#
cat<< EOF >/etc/elastiq.conf 
[elastiq]
check_queue_every_s = 45
idle_for_time_s = $IDLE_TIME
waiting_jobs_time_s = 45
n_jobs_per_vm = $JOBS_PER_VM
batch_plugin = htcondor
estimated_vm_deploy_time_s = 1200
check_vms_every_s = 45

[ec2]
flavour = $FLAVOR
api_url = $EC2_URL
user_data_b64 = $SLAVE_USERDATA
image_id = $IMAGE_ID
aws_secret_access_key = $EC2_SECRET_KEY
aws_access_key_id = $EC2_ACCESS_KEY
key_name = $KEY_NAME

[quota]
max_vms = $MAX_VMS
min_vms = $MIN_VMS

EOF
sed -i "s|Activity,Machine|Machine,MyType,Activity,TargetType|g" /usr/lib/python2.7/site-packages/elastiq/plugins/htcondor.py
sed -i "s|'condor_q', '-global', '-attributes', 'JobStatus', '-long'|'condor_q', '-all', '-global', '-attributes', 'JobStatus', '-long'|g" /usr/lib/python2.7/site-packages/elastiq/plugins/htcondor.py
#
service elastiq start
#
adduser scientific
mkdir /home/scientific/jobs/
mkdir /home/scientific/jobs/log/
mkdir /home/scientific/jobs/output/
mkdir /home/scientific/jobs/error/
cat<< EOF > /home/scientific/jobs/test.jdl
Universe = vanilla
Executable = /home/scientific/jobs/test.sh
Log = /home/scientific/jobs/log/test.log.\$(Cluster).\$(Process)
Output = /home/scientific/jobs/output/test.out.\$(Cluster).\$(Process)
Error = /home/scientific/jobs/error/test.err.\$(Cluster).\$(Process)
Queue 10
EOF
cat<< EOF > /home/scientific/jobs/test-docker.jdl
universe                = docker
docker_image            = debian
executable              = /bin/cat
arguments               = /etc/hosts
should_transfer_files   = YES
when_to_transfer_output = ON_EXIT
Log = /home/scientific/jobs/log/test-docker.log.\$(Cluster).\$(Process)
Output = /home/scientific/jobs/output/test-docker.out.\$(Cluster).\$(Process)
Error = /home/scientific/jobs/error/test-docker.err.\$(Cluster).\$(Process)
request_memory          = 100M
Queue 10
EOF
cat /tmp/test.sh > /home/scientific/jobs/test.sh
chown scientific:root -R /home/scientific/jobs/
chmod u+x -R /home/scientific/jobs/
#
cat<<EOF>/root/README.txt
Root user can't submit condor jobs.
You can submit jobs using scientific user [ su - scientific ] and you can test condor using the test.jdl file [ condor_submit jobs/test.jdl ].
Good fun! :)
EOF
